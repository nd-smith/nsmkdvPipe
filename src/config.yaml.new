# =============================================================================
# Kafka Pipeline Configuration (New Hierarchical Structure)
# =============================================================================
# This configuration has been converted from the legacy flat structure to the
# new hierarchical format organized by domain (xact/claimx) and worker.
# =============================================================================

# =============================================================================
# PIPELINE EVENT SOURCE
# =============================================================================
event_source: "eventhouse"

# =============================================================================
# KAFKA CONFIGURATION
# =============================================================================
kafka:
  # ---------------------------------------------------------------------------
  # Global Connection Settings
  # ---------------------------------------------------------------------------
  bootstrap_servers: "localhost:9094"
  security_protocol: "PLAINTEXT"
  sasl_mechanism: "OAUTHBEARER"
  sasl_plain_username: ""
  sasl_plain_password: ""

  # ---------------------------------------------------------------------------
  # Topic and Consumer Group Prefixes
  # ---------------------------------------------------------------------------
  topic_prefix: ""  # No prefix (topics use full names like "xact.events.raw")
  consumer_group_prefix: "xact"

  # ---------------------------------------------------------------------------
  # Global Default Settings for All Consumers
  # ---------------------------------------------------------------------------
  defaults:
    consumer:
      auto_offset_reset: "earliest"
      enable_auto_commit: false
      max_poll_records: 3000
      max_poll_interval_ms: 60000  # 1 minute
      session_timeout_ms: 60000
      heartbeat_interval_ms: 3000  # Must be < session_timeout_ms/3
      fetch_min_bytes: 1
      fetch_max_wait_ms: 500

    producer:
      acks: "all"
      retries: 3
      retry_backoff_ms: 1000
      max_request_size: 200485760  # 200MB
      compression_type: "lz4"
      linger_ms: 10
      batch_size: 16384

  # ---------------------------------------------------------------------------
  # XACT Domain Configuration
  # ---------------------------------------------------------------------------
  xact:
    # Topic name overrides (explicit names from your old config)
    topics:
      events: "xact.events.raw"
      downloads_pending: "xact.downloads.pending"
      downloads_cached: "xact.downloads.cached"
      downloads_results: "xact.downloads.results"
      dlq: "xact.downloads.dlq"

    # Event Ingester Worker
    event_ingester:
      processing:
        health_port: 8080
      # Uses default consumer/producer settings

    # Download Worker
    download_worker:
      processing:
        concurrency: 10  # From old download_concurrency
        batch_size: 20   # From old download_batch_size
        timeout_seconds: 60
      consumer:
        max_poll_records: 20  # Override default for batch processing

    # Upload Worker
    upload_worker:
      processing:
        concurrency: 25  # From old upload_concurrency
        batch_size: 30   # From old upload_batch_size
      consumer:
        max_poll_records: 30  # Match batch_size

    # Delta Events Writer
    delta_events_worker:
      processing:
        batch_size: 2000  # From old delta_events_batch_size
        max_batches: null  # From old delta_events_max_batches (null = unlimited)
      producer:
        # Uses default producer settings
        acks: "all"

  # ---------------------------------------------------------------------------
  # ClaimX Domain Configuration
  # ---------------------------------------------------------------------------
  claimx:
    # Topic name overrides
    topics:
      events: "claimx.events.raw"
      enrichment_pending: "claimx.enrichment.pending"
      downloads_pending: "claimx.downloads.pending"
      downloads_cached: "claimx.downloads.cached"
      downloads_results: "claimx.downloads.results"
      dlq: "claimx.downloads.dlq"

    # Event Ingester Worker
    event_ingester:
      processing:
        health_port: 8084
      # Uses default consumer/producer settings

    # Enrichment Worker (ClaimX-specific)
    enrichment_worker:
      processing:
        batch_size: 3000  # From claimx.processing.batch_size
        batch_timeout_seconds: 5.0
        api_concurrency: 20  # From claimx.api.max_concurrent
        health_port: 8081
      consumer:
        max_poll_records: 3000

    # Download Worker
    download_worker:
      processing:
        concurrency: 40  # From claimx.download.max_concurrent
        batch_size: 40
        timeout_seconds: 120  # From claimx.download.timeout_seconds
        health_port: 8082
      consumer:
        max_poll_records: 40

    # Upload Worker
    upload_worker:
      processing:
        concurrency: 25
        batch_size: 30
        health_port: 8083
      consumer:
        max_poll_records: 30

# =============================================================================
# ONELAKE STORAGE PATHS
# =============================================================================
onelake:
  domain_paths:
    xact: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Files/veriskPipeline/xact"
    claimx: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Files/veriskPipeline/claimx"
  base_path: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Files/veriskPipeline"

# Cache directory for downloads
cache_dir: "/tmp/kafka_pipeline_cache"

# =============================================================================
# RETRY CONFIGURATION
# =============================================================================
retry:
  delays: [300, 600, 1200, 2400]  # 5min, 10min, 20min, 40min

# =============================================================================
# EVENTHOUSE INTEGRATION (for Kafka pipeline event source)
# =============================================================================
eventhouse:
  # Connection settings
  cluster_url: "https://trd-atjd28cdnn65pbxjek.z8.kusto.fabric.microsoft.com"
  database: "VERISK_XACTANALYSIS_DB"

  # Query settings
  query_timeout_seconds: 240
  max_retries: 5
  retry_base_delay_seconds: 10
  retry_max_delay_seconds: 30.0
  max_connections: 5

  # Poller settings
  poller:
    poll_interval_seconds: 15
    batch_size: 20000
    source_table: "tbl_VERISK_XACTANALYSIS_STATUS_EXPORT"
    events_table_path: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Tables/dbo/xact_events"

    # Backfill settings
    backfill_start_stamp: null
    backfill_stop_stamp: null
    bulk_backfill: false

    # Backpressure settings
    max_kafka_lag: 10000
    lag_check_interval_seconds: 60

    # Column mapping
    column_mapping:
      trace_id: "trace_id"
      event_type: "event_type"
      event_subtype: "event_subtype"
      timestamp: "timestamp"
      source_system: "source_system"
      payload: "payload"
      attachments: "attachments"

  # Deduplication settings
  dedup:
    xact_events_table_path: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Tables/dbo/xact_events"
    xact_events_window_hours: 25
    eventhouse_query_window_hours: 24
    overlap_minutes: 5
    max_trace_ids_per_query: 500000
    kql_start_stamp: "2026-1-05 00:00:00.000001"

# =============================================================================
# XACT PIPELINE (Legacy Verisk pipeline)
# =============================================================================
xact:
  # Kusto/Eventhouse connection
  kusto:
    cluster_uri: "https://trd-atjd28cdnn65pbxjek.z8.kusto.fabric.microsoft.com"
    database: "VERISK_XACTANALYSIS_DB"
    table_name: "tbl_VERISK_XACTANALYSIS_STATUS_EXPORT"

  # Lakehouse/OneLake settings
  lakehouse:
    abfss_path: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Tables/dbo"
    events_table: "xact_events"
    attachments_table: "xact_attachments"
    retry_table: "xact_retry"
    files_path: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Files/veriskPipeline/xact"

    # Batch size limits
    max_batch_size_retry_queue: 1000
    max_batch_size_inventory: 10000
    max_batch_size_merge: 100000
    max_batch_size_read: 50000

    # Upload concurrency
    upload_max_concurrency: 16
    upload_block_size_mb: 4
    upload_max_single_put_mb: 64

    # Cache limits
    max_cache_size_completed_ids: 1000000

  # Event processing
  processing:
    event_types:
      - "xact.assignment.*"
    status_subtypes:
      - "documentsReceived"
      - "firstNoticeOfLossReceived"
      - "estimatePackageReceived"
    start_date: "2025-01-01T00:00:00"
    batch_size: 100
    max_events_to_scan: 5000
    lookback_days: 1

  # Download settings
  download:
    max_concurrent: 10
    timeout_seconds: 60
    max_retries: 3

  # Retry stage settings
  retry:
    enabled: true
    batch_size: 50
    min_retry_age_seconds: 300
    max_retries: 3
    backoff_base_seconds: 300
    backoff_multiplier: 2.0
    max_concurrent: 5
    retention_days: 30
    cleanup_on_start: true

  # Scheduling
  schedule:
    interval_seconds: 60
    enabled_stages:
      - "ingest"
      - "download"
      - "retry"

  # Security
  security:
    allowed_download_domains:
      - "usw2-prod-xn-exportreceiver-publish.s3.us-west-2.amazonaws.com"
    encrypt_temp_files: false
    audit_logging_enabled: true
    audit_log_path: "/var/log/verisk_pipeline/audit.log"
    key_vault_url: ""
    service_principal_secret_name: "service-principal-secret"
    subscription_id: ""
    resource_group: ""
    client_id: ""
    tenant_id: ""

  # Timeouts
  timeouts:
    kusto_query_timeout: 300
    kusto_request_timeout: 30
    onelake_connection_timeout: 300
    onelake_request_timeout: 300
    onelake_read_timeout: 300
    http_connection_timeout: 30
    http_read_timeout: 300

# =============================================================================
# CLAIMX PIPELINE (ClaimXperience pipeline)
# =============================================================================
claimx:
  # Kusto/Eventhouse connection
  kusto:
    cluster_uri: "https://trd-atjd28cdnn65pbxjek.z8.kusto.fabric.microsoft.com"
    database: "VERISK_CLAIMXPERIENCE_DB"
    events_table: "tbl_CLAIMXPERIENCE_EVENTS"

  # ClaimX REST API
  api:
    base_url: "https://www.claimxperience.com/service/cxedirest"
    auth_token_env: "CLAIMX_API_TOKEN"
    _auth_token: "am9yZGFuc211aW46cERIZjF5ZnhkVXpKMU1aSnROcno="
    timeout_seconds: 30
    max_concurrent: 20

  # Lakehouse/OneLake settings
  lakehouse:
    abfss_path: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Tables/dbo"
    files_path: "abfss://7729c159-0674-42ba-abf7-a6756723c62f@onelake.dfs.fabric.microsoft.com/584315ee-2f41-4943-949f-901d438bcd36/Files/veriskPipeline"

    # Event log (from Kusto)
    events_table: "claimx_events"

    # Entity tables (from API enrichment)
    projects_table: "claimx_projects"
    contacts_table: "claimx_contacts"
    media_metadata_table: "claimx_attachment_metadata"
    tasks_table: "claimx_tasks"
    task_templates_table: "claimx_task_templates"
    external_links_table: "claimx_external_links"
    video_collab_table: "claimx_video_collab"

    # Processing tracking
    event_log_table: "claimx_event_log"
    attachments_table: "claimx_attachments"
    retry_table: "claimx_retry"

  # Event processing
  processing:
    event_types:
      - "PROJECT_CREATED"
      - "PROJECT_FILE_ADDED"
      - "PROJECT_MFN_ADDED"
      - "CUSTOM_TASK_ASSIGNED"
      - "CUSTOM_TASK_COMPLETED"
      - "POLICYHOLDER_INVITED"
      - "POLICYHOLDER_JOINED"
      - "VIDEO_COLLABORATION_INVITE_SENT"
      - "VIDEO_COLLABORATION_COMPLETED"
      - "PROJECT_CONVERSATION_UPDATED"
      - "PERSONAL_PROPERTY_TASK_SHARED"
      - "PROJECT_AUTO_XA_LINKING_UNSUCCESSFUL"
    batch_size: 3000
    max_events_to_scan: 3000
    lookback_days: 1
    start_date: "2025-01-01T00:00:00"
    skip_dedup_check: false

  # Download settings
  download:
    max_concurrent: 40
    timeout_seconds: 120
    proxy: "http://bobswebproxy.igslb.allstate.com:8080"

  # Retry stage settings
  retry:
    enabled: true
    batch_size: 600
    min_retry_age_seconds: 30
    max_retries: 3
    backoff_base_seconds: 30
    backoff_multiplier: 1.5
    max_concurrent: 25
    retention_days: 7
    cleanup_on_start: true

  # Scheduling
  schedule:
    interval_seconds: 60
    enabled_stages:
      - "ingest"
      - "enrich"
      - "download"
      - "retry"

  # Security
  security:
    allowed_download_domains:
      - "claimxperience.s3.amazonaws.com"
      - "claimxperience.s3.us-east-1.amazonaws.com"
      - "www.claimxperience.com"
      - "xactware-claimx-us-prod.s3.us-west-1.amazonaws.com"
      - "claimxperience.com"
    audit_logging_enabled: true
    audit_log_path: "logs/claimx_audit.log"
    encrypt_temp_files: false

# =============================================================================
# SHARED SETTINGS
# =============================================================================
health:
  enabled: true
  host: "127.0.0.1"
  port: 8080

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_dir: "logs"

observability:
  json_logs: true
  log_upload_enabled: true
  log_upload_interval_cycles: 10
  log_retention_days: 7
  memory_checkpoints_enabled: true
  memory_checkpoint_level: "DEBUG"
  memory_profiling_enabled: true
  memory_snapshot_interval: 5
  memory_alert_threshold_mb: 4096

# Runtime metadata
worker_id: "worker-01"
test_mode: false
